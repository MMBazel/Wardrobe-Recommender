{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE Capstone: Outfit Recommender - Spring 2021\n",
    "# Step 2: Data Collection & Initial EDA of Candidate Datasets\n",
    "\n",
    "### By: Bazeley, Mikiko \n",
    "### GH: @mmbazel  \n",
    "\n",
    "In this section, we'll explore & analyze potential candidate datasets. \n",
    "For more information about the project, please check out the project wiki. \n",
    "\n",
    "Specifically in this notebook we'll: \n",
    "* Explore 3 datasets\n",
    "* Take initial steps to systemize the data acquisition\n",
    "* Provide a sample view of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### [TODO] SETUP #####################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gdown\n",
    "\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Packages Imported')\n",
    "# [TODO] Package install/load\n",
    "# [TODO] Import any utilities functions\n",
    "# [TODO] Set any settings\n",
    "# [TODO] Load any secrets/credetials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "modules = dir()\n",
    "\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] Query & download metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################ \n",
    "#################### Getting the metadata ####################\n",
    "######################################## ####################\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=0B7EVK8r0v71pWnFiNlNGTVloLUk'\n",
    "output = 'list_category_cloth.txt'\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=0B7EVK8r0v71pTGNoWkhZeVpzbFk'\n",
    "output = 'list_category_img.txt'\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=0B7EVK8r0v71pdS1FMlNreEwtc1E'\n",
    "output = 'list_eval_partition.txt'\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] Query & download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################ \n",
    "#################### Getting the actual images ####################\n",
    "######################################## ####################\n",
    "\n",
    "root_path = './'\n",
    "url = 'https://drive.google.com/uc?id=1j5fCPgh0gnY6v7ChkWlgnnHH6unxuAbb'\n",
    "output = 'img.zip'\n",
    "gdown.download(url, output, quiet=False)\n",
    "with zipfile.ZipFile(\"img.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] Once we get images & metadata, combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################ \n",
    "#################### Creating the master dataset ####################\n",
    "######################################## ####################\n",
    "\n",
    "\n",
    "category_list = []\n",
    "image_path_list = []\n",
    "data_type_list = []\n",
    "# category names\n",
    "with open('list_category_cloth.txt', 'r') as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "        if i > 1:\n",
    "            category_list.append(line.split(' ')[0])\n",
    "\n",
    "# category map\n",
    "with open('list_category_img.txt', 'r') as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "        if i > 1:\n",
    "            image_path_list.append([word.strip() for word in line.split(' ') if len(word) > 0])\n",
    "\n",
    "\n",
    "# train, valid, test\n",
    "with open('list_eval_partition.txt', 'r') as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "        if i > 1:\n",
    "            data_type_list.append([word.strip() for word in line.split(' ') if len(word) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(image_path_list, columns=['image_path', 'category_number'])\n",
    "data_df['category_number'] = data_df['category_number'].astype(int)\n",
    "data_df = data_df.merge(pd.DataFrame(data_type_list, columns=['image_path', 'dataset_type']), on='image_path')\n",
    "data_df['category'] = data_df['category_number'].apply(lambda x: category_list[int(x) - 1])\n",
    "data_df = data_df.drop('category_number', axis=1)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] Do initial EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################ \n",
    "#################### EDA ####################\n",
    "######################################## ####################\n",
    "\n",
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################ \n",
    "#################### EDA ####################\n",
    "######################################## ####################\n",
    "\n",
    "data_df[['image_path','dataset_type']].groupby('dataset_type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################ \n",
    "#################### EDA ####################\n",
    "######################################## ####################\n",
    "\n",
    "\n",
    "len(data_df.category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################ \n",
    "#################### EDA ####################\n",
    "######################################## ####################\n",
    "\n",
    "\n",
    "\n",
    "data_df[['image_path','category']].groupby('category').count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
